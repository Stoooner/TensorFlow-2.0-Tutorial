{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时106 tensorflow自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow Version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensorflow Version:', tf.__version__)"
   ]
  },
  {
   "source": [
    "## 1. 自定义全连接层(dense)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        # 首先继承父类tf.keras.layers.Layer的属性\n",
    "        super(Linear, self).__init__()\n",
    "        # 初始化权重\n",
    "        # add_weights方法继承自父类的方法\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.weight = tf.Variable(initial_value=w_init(shape=(input_dim, units),                                                              dtype='float32'),\n",
    "                                  trainable=True)\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.bias = tf.Variable(initial_value=b_init(shape=(units,),dtype='float32'), \n",
    "                                trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.00104036,  0.00183899, -0.00479256, -0.07462753],\n",
       "       [ 0.00104036,  0.00183899, -0.00479256, -0.07462753]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x = tf.ones(shape=(2,2))\n",
    "hidden_layer = Linear(units=4, input_dim=2)\n",
    "y = hidden_layer(inputs=x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[-0.06415289, -0.10509486, -0.05924907,  0.08822808],\n",
       "        [-0.07400787,  0.00171867, -0.04386234, -0.12518638]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "hidden_layer.weights"
   ]
  },
  {
   "source": [
    "## 2. 为层添加权重\n",
    ">还可以使用add_weights的方法为层更加快捷的添加权重"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        # 首先继承父类tf.keras.layers.Layer的属性\n",
    "        super(Linear, self).__init__()\n",
    "        # 初始化权重\n",
    "        # add_weight方法继承自父类的方法\n",
    "        self.weight = self.add_weight(shape=(input_dim, units),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(shape=(units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.08450989,  0.06303281,  0.02029446, -0.02093529],\n",
       "       [ 0.08450989,  0.06303281,  0.02029446, -0.02093529]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "x = tf.ones(shape=(2,2))\n",
    "hidden_layer = Linear(units=4, input_dim=2)\n",
    "y = hidden_layer(inputs=x)\n",
    "y"
   ]
  },
  {
   "source": [
    "## 3. 推迟权重创建到输入shape知晓以后"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "x = tf.keras.layers.Dense(units=64)\n",
    "x.weights"
   ]
  },
  {
   "source": [
    "因此我们可以在我们的自定义层中加入build(self, input_shape)方法中创建层的权重"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        # 首先继承父类tf.keras.layers.Layer的属性\n",
    "        super(Linear, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # 初始化权重\n",
    "        # add_weight方法继承自父类的方法\n",
    "        # input_shape = [batch_num, data_dim], input_shape[-1] = data_dim\n",
    "        self.weight = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                                      initializer='random_normal',\n",
    "                                      trainable=True)\n",
    "        self.bias = self.add_weight(shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "hidden_layer = Linear(units=4)\n",
    "hidden_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[ 0.07163899, -0.03818507, -0.04971079,  0.06779702],\n",
       "       [ 0.07163899, -0.03818507, -0.04971079,  0.06779702]],\n",
       "      dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x = tf.ones(shape=(2,2))\n",
    "y = hidden_layer(inputs=x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'linear/Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       " array([[ 0.07849186, -0.00700583, -0.06317079,  0.07516818],\n",
       "        [-0.00685288, -0.03117924,  0.01346   , -0.00737116]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'linear/Variable:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "hidden_layer.weights"
   ]
  },
  {
   "source": [
    "## 4. 层可以递归组合\n",
    ">如果将一个层实例分配为另一个层的特性，则外部层将开始追踪内部层的权重。我们建议在init()方法中创建此类子层(由于子层通常具有构建方法，它们将与外部层同时构建)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Block(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLP_Block, self).__init__()\n",
    "        # Linear就是子层\n",
    "        self.linear_1 = Linear(units=32)\n",
    "        self.linear_2 = Linear(units=64)\n",
    "        self.linear_3 = Linear(units=1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.linear_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_Block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Block2(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(MLP_Block, self).__init__()\n",
    "        # Linear就是子层\n",
    "        self.linear_1 = tf.keras.layers.Dense(units=32)\n",
    "        self.linear_2 = tf.keras.layers.Dense(units=64)\n",
    "        self.linear_3 = tf.keras.layers.Dense(units=32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x1 = self.linear_1(inputs)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        x2 = self.linear_2(x1)\n",
    "        x2 = tf.nn.relu(x2)\n",
    "        x3 = self.linear_3(x2)\n",
    "        return tf.concat([x1, x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_Block2()"
   ]
  },
  {
   "source": [
    "## 5. 自定义模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP_Model, self).__init__()\n",
    "        # Linear就是子层\n",
    "        self.linear_1 = tf.keras.layers.Dense(units=32)\n",
    "        self.linear_2 = tf.keras.layers.Dense(units=64)\n",
    "        self.linear_3 = tf.keras.layers.Dense(units=32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x1 = self.linear_1(inputs)\n",
    "        x1 = tf.nn.relu(x1)\n",
    "        x2 = self.linear_2(x1)\n",
    "        x2 = tf.nn.relu(x2)\n",
    "        x3 = self.linear_3(x2)\n",
    "        return tf.concat([x1, x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP_Model()"
   ]
  },
  {
   "source": [
    "继承自Model相比继承自Layers多出的一些方法："
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Model.fit of <__main__.MLP_Model object at 0x00000133543A47C8>>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Model.save of <__main__.MLP_Model object at 0x00000133543A47C8>>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "97f51838a204c4b091d88d85c2d4baf8f02dc46ee5458c8812c2639c909172ca"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}