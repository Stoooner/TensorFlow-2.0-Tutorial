{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时117 TF2.0-UNet语义分割模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据的图片\n",
    "train_imgs = glob.glob('../cityscapes/leftImg8bit/train/*/*.png')\n",
    "# 读取训练数据的标签\n",
    "train_labels = glob.glob('../cityscapes/gtFine/train/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对训练集进行乱序\n",
    "index = np.random.permutation(len(train_imgs))\n",
    "train_imgs = np.array(train_imgs)[index]\n",
    "train_labels = np.array(train_labels)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取交叉验证数据的图片\n",
    "val_imgs = glob.glob('../cityscapes/leftImg8bit/val/*/*.png')\n",
    "# 读取交叉验证数据的标签\n",
    "val_labels = glob.glob('../cityscapes/gtFine/val/*/*_gtFine_labelIds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建dataset\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((val_imgs, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义读取图片的函数\n",
    "def read_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    return img\n",
    "\n",
    "# 定义读取标签的函数\n",
    "def read_png_label(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = read_png(train_imgs[0])\n",
    "label_1 = read_png_label(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据增强\n",
    "1. 随机翻转：img = tf.image.flip_left_right()\n",
    "2. 随机裁切：由于原始图像和分割标签图像是匹配的，所以需要将两者按照通道方向进行合并，然后再随机裁切，又由于图像比较大，如果直接塞到模型，可能显存不够用，因此可以将图像先resize到较小的尺寸，再在较小尺寸上进行随机裁切，这样获取到的图像视野能够比较大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, mask):\n",
    "    # 先将原始图像和分割标签进行合并（沿着图像的通道方向）\n",
    "    concat_img = tf.concat([img, mask], axis=-1)\n",
    "    concat_img = tf.image.resize(concat_img, (280, 280), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n",
    "    # 需要注意的是如果mask=crop_img[:, :, 3]，则返回的是一个二维的图像，channel维度被切片切掉了\n",
    "    # 而mask = crop_img[:, :, 3:]则代表channel那个维度的1会被保留下来\n",
    "    return crop_img[:, :, :3], crop_img[:, :, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1, label_1 = crop_img(img_1, label_1)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_1.numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入的原始图像做归一化\n",
    "def normal(img, mask):\n",
    "    img = tf.cast(img, tf.float32) / 127.5 - 1\n",
    "    mask = tf.cast(mask, tf.int32)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "def load_image_train(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img, mask = crop_img(img, mask)\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载验证集数据\n",
    "def load_image_val(img_path, mask_path):\n",
    "    img = read_png(img_path)\n",
    "    mask = read_png_label(mask_path)\n",
    "    \n",
    "    img = tf.image.resize(img, (256, 256))\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    \n",
    "    img, mask = normal(img, mask)\n",
    "    return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型的一些常量\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 300\n",
    "train_step_per_epoch = len(train_imgs) // BATCH_SIZE\n",
    "val_step_per_epoch = len(val_imgs) // BATCH_SIZE\n",
    "\n",
    "auto = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# 获取dataset\n",
    "dataset_train = dataset_train.map(load_image_train, num_parallel_calls=auto)\n",
    "dataset_val = dataset_val.map(load_image_val, num_parallel_calls=auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, m in dataset_train.take(1):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow((img_1.numpy()+1)/2)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(label_1.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(auto)\n",
    "dataset_val = dataset_val.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看标签有多少类\n",
    "np.unique(label_1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. UNet模型搭建(使用自定义层)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自定义层定义相应的下采样模块\n",
    "class Downsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv_layer_1 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                                   kernel_size=3,\n",
    "                                                   padding=\"same\")\n",
    "        self.conv_layer_2 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                                   kernel_size=3,\n",
    "                                                   padding=\"same\")\n",
    "        self.pool_layer = tf.keras.layers.MaxPooling2D()\n",
    "    \n",
    "    def call(self, x, is_pool=True):\n",
    "        if is_pool:\n",
    "            x = self.pool_layer(x)\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自定义层定义相应的上采样模块\n",
    "class Upsample(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv_layer_1 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                                   kernel_size=3,\n",
    "                                                   padding=\"same\")\n",
    "        self.conv_layer_2 = tf.keras.layers.Conv2D(filters=filters,\n",
    "                                                   kernel_size=3,\n",
    "                                                   padding=\"same\")\n",
    "        self.deconv_layer = tf.keras.layers.Conv2DTranspose(filters=filters//2,\n",
    "                                                            kernel_size=3,\n",
    "                                                            strides=2,\n",
    "                                                            padding=\"same\")\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.deconv_layer(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(UNet_model, self).__init__()\n",
    "        self.downsample_1 = Downsample(filters=64)\n",
    "        self.downsample_2 = Downsample(filters=128)\n",
    "        self.downsample_3 = Downsample(filters=256)\n",
    "        self.downsample_4 = Downsample(filters=512)\n",
    "        self.downsample_5 = Downsample(filters=1024)\n",
    "        self.upsample_0 = tf.keras.layers.Conv2DTranspose(filters=512,\n",
    "                                                          kernel_size=2,\n",
    "                                                          strides=2,\n",
    "                                                          padding=\"same\")\n",
    "        self.upsample_1 = Upsample(filters=512)\n",
    "        self.upsample_2 = Upsample(filters=256)\n",
    "        self.upsample_3 = Upsample(filters=128)\n",
    "        self.second_output_layer = Downsample(filters=64)\n",
    "        self.last_output_layer = tf.keras.layers.Conv2D(filters=34,\n",
    "                                                        kernel_size=1,\n",
    "                                                        padding=\"same\")\n",
    "    def call(self, x):\n",
    "        x1 = self.downsample_1(x, is_pool=False)\n",
    "        x2 = self.downsample_2(x1)\n",
    "        x3 = self.downsample_3(x2)\n",
    "        x4 = self.downsample_4(x3)\n",
    "        x5 = self.downsample_5(x4)\n",
    "        x5 = self.upsample_0(x5)\n",
    "\n",
    "        x5 = tf.concat([x4, x5])\n",
    "        x5 = self.upsample_1(x5)\n",
    "\n",
    "        x5 = tf.concat([x3, x5])\n",
    "        x5 = self.upsample_2(x5)\n",
    "\n",
    "        x5 = tf.concat([x2, x5])\n",
    "        x5 = self.upsample_3(x5)\n",
    "\n",
    "        x5 = tf.concat([x1, x5])\n",
    "        x5 = self.second_output_layer(x5, is_pool=False)\n",
    "        x5 = self.last_output_layer(x5)\n",
    "        return x5"
   ]
  },
  {
   "source": [
    "## 4. 定义优化器，损失函数等"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet_model()\n",
    "opt = tf.keras.optimizers.Adam(0.0001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义IOU指标\n",
    "class MeanIOU(tf.keras.metrics.MeanIoU):\n",
    "    def __call__(self, y_true, y_pred):\n",
    "        y_pred = tf.argmax(y_pred)\n",
    "        return super().__call__(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\n",
    "train_iou = MeanIOU(34, name='train_iou')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\n",
    "test_iou = MeanIOU(34, name='test_iou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        pred = model(images)\n",
    "        loss_step = loss_fn(labels, pred)\n",
    "    grads = t.gradient(loss_step, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss_step)\n",
    "    train_acc(labels, pred)\n",
    "    train_iou(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    pred = model(images)\n",
    "    loss_step = loss_fn(labels, pred)\n",
    "\n",
    "    test_loss(loss_step)\n",
    "    test_acc(labels, pred)\n",
    "    test_iou(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    train_iou.reset_states()\n",
    "\n",
    "    test_loss.reset_states()\n",
    "    test_acc.reset_states()\n",
    "    test_iou.reset_states()\n",
    "\n",
    "    for images, labels in dataset_train:\n",
    "        train_step(images, labels)\n",
    "    \n",
    "    for test_images, test_labels in dataset_val:\n",
    "        test_step(test_images, test_labels)\n",
    "    \n",
    "    template = 'Epoch: {:.3f}, Loss {:.3f}, Accuracy {:.3f}, \\\n",
    "                IOU {:.3f}, Test Loss {:.3f}, Test Accuracy {:.3f}\\\n",
    "                , Test IOU {:.3f}'\n",
    "    print(template.format(epoch+1,\n",
    "                          train_loss.result(),\n",
    "                          train_acc.result()*100,\n",
    "                          train_iou.result(),\n",
    "                          test_loss.result(),\n",
    "                          test_acc.result()*100,\n",
    "                          test_iou.result()))"
   ]
  },
  {
   "source": [
    "## 5. 查看模型训练效果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training_loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation_loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看模型训练完毕之后的效果\n",
    "num = 3\n",
    "for image, mask in dataset_val.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num):\n",
    "        plt.subplot(num, 3, i*num+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n",
    "        plt.subplot(num, 3, i*num+2)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n",
    "        plt.subplot(num, 3, i*num+3)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "24a5e97bb7b9e502cdc0a8f9a9ca55a530ba47ae30463d9079b7951f45a334c6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}