{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课时45 变量与自动微分运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tensorflow Version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "sb.set_style('darkgrid')\n",
    "# pathlib相比os.path更好用\n",
    "import pathlib\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "print('Tensorflow Version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Variable变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要注意的是tf.Variable得到的变量是整个模型中可以进行更改更新的参数\n",
    "v = tf.Variable(0.0)\n",
    "(v + 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=5.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面展示如何直接修改变量的值\n",
    "v.assign(5)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign_add(1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=32, shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.read_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 自动微分运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# tape 磁带，会自动的跟踪记录一个变量的计算过程，然后方便进行微分计算\n",
    "w = tf.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w * w\n",
    "# t.gradient(target=loss, sources=w)代表的是目标target对变量w的微分\n",
    "grad = tape.gradient(target=loss, sources=w)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[6.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 如果是一个常量的话，要计算其微分，需要给定tf.GradientTape()一些要求以便记录下运算过程\n",
    "w2 = tf.constant([[3.0]])\n",
    "with tf.GradientTape() as t:\n",
    "    # watch用于记录常量的运算过程\n",
    "    t.watch(w2)\n",
    "    loss2 = w2 * w2\n",
    "# t.gradient(target=loss, sources=w)代表的是目标target对变量w的微分\n",
    "grad2 = t.gradient(target=loss2, sources=w2)\n",
    "grad2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意两点：\n",
    ">1. 自动微分运算对于变量(Variable)和常量(Constant)的跟踪，它都要求这两个是float数据类型, 否则是求解不出梯度的；\n",
    ">2. 对于tf.GradientTape()所持有的资源(也就是记录的这些运算)，在我们调用了t.gradient()方法之后会立即释放这些资源，这个意思就是说在同一次计算中如果我们要计算多个微分的话，这个时候是不行的，因为t计算一次就会将资源释放，如果要计算多个变量多次微分的话，这个时候需要在tf.GradientTape()中添加一个参数，也就是persistent=True，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[108.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 如果是一个常量的话，要计算其微分，需要给定tf.GradientTape()一些要求以便记录下运算过程\n",
    "w3 = tf.constant([[3.0]])\n",
    "# persistent=True会让tf.GradientTape()持久，而不是t.gradient()运行完之后就释放资源\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "    # watch用于记录常量的运算过程\n",
    "    t.watch(w3)\n",
    "    y = w3 * w3\n",
    "    z = y * y\n",
    "# t.gradient(target=loss, sources=w)代表的是目标target对变量w的微分\n",
    "dy_dw = t.gradient(target=y, sources=w3)\n",
    "dz_dw = t.gradient(target=z, sources=w3)\n",
    "# 这里直接调用的话会爆RuntimeError，因为在第一个t.gradient()运行完之后资源已经释放了\n",
    "# dy_dw\n",
    "dz_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用tf.GradientTape实现梯度下降以及自定义的训练与循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((28, 28, 1), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载MNIST数据集\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "# 以tf.Dataset形式加载数据(对于MNIST数据集，它是没有第三个维度Channel的，这里添加上它的第三个维度)\n",
    "train_images = tf.expand_dims(train_images, -1)\n",
    "# 由于tf.GradientTape()要求的数据类型是float，因此这里需要改变MNIST数据集图片的数据类型\n",
    "# 并在转换数据类型的过程中对图片数据进行归一化\n",
    "train_images = tf.cast(train_images/255, tf.float32)\n",
    "# 对于MNIST数据集的标签，数据类型是uint8(无符号8位)，这里为了方便计算，将其转换为int64类型\n",
    "train_labels = tf.cast(train_labels, tf.int64)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "\n",
    "test_images = tf.expand_dims(test_images, -1)\n",
    "test_images = tf.cast(test_images/255, tf.float32)\n",
    "test_labels = tf.cast(test_labels, tf.int64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对数据进行打乱以及batch划分\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = test_dataset.batch(batch_size=32)\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=[3, 3], activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=[3, 3], activation='relu'),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(units=10, activation='softmax')])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行自定义训练\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# 由于dataset是tf.Dataset对象，因此在eager模型下是直接可迭代的(这里设定了batch=32，因此每次迭代都取出32个数据)：\n",
    "features, labels = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1305823, shape=(32,), dtype=int64, numpy=\n",
       "array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=int64)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model内置call方法，因此可以直接调用\n",
    "predictions = model(features)\n",
    "# 还没进行训练的时候预测的进度不好\n",
    "tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数，每次传入数据之后都会返回相应的损失值\n",
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return loss_func(y, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个tf.keras.metrics对象用于计算自定义训练中的loss均值和正确率\n",
    "train_loss = tf.keras.metrics.Mean('train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean('test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一步对应的损失函数与模型参数的梯度\n",
    "def train_step(model, images, labels):\n",
    "    with tf.GradientTape() as t:\n",
    "        # loss_step = loss(model, images, labels)\n",
    "        # 为了方便tf.keras.metrics模块的演示，将上面这个代码拆成两步，不再调用loss计算函数\n",
    "        pred = model(images)\n",
    "        loss_step = loss_func(labels, pred)\n",
    "    grads = t.gradient(loss_step, model.trainable_variables)\n",
    "    # apply_gradients()代表将优化方法应用到参数的更新中\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # 这里是新增的部分，每一步都计算均值和正确率\n",
    "    train_loss(loss_step)\n",
    "    train_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一步对应的损失函数与模型参数的梯度\n",
    "def test_step(model, images, labels):\n",
    "    pred = model(images)\n",
    "    loss_step = loss_func(labels, pred)\n",
    "    test_loss(loss_step)\n",
    "    test_accuracy(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # 训练3个epochs\n",
    "    for epoch in range(3):\n",
    "        for (batch, (images, labels)) in enumerate(dataset):\n",
    "            train_step(model, images, labels)\n",
    "        print('Epoch %i loss is %f, acc is %f'%(epoch, \n",
    "                                                train_loss.result(),\n",
    "                                                train_accuracy.result()))\n",
    "        # 每个batch结束就重置这一轮的train_loss和train_accuracy\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        \n",
    "        # ------------------------------------------------------------\n",
    "        for (batch, (images, labels)) in enumerate(test_dataset):\n",
    "            test_step(model, images, labels)\n",
    "        print('Epoch %i test_loss is %f, test_acc is %f'%(epoch, \n",
    "                                                test_loss.result(),\n",
    "                                                test_accuracy.result()))\n",
    "        \n",
    "        # 每个batch结束就重置这一轮的train_loss和train_accuracy\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. tf.keras.metrics汇总计算模块\n",
    "tf.keras.metrics这个模型用于计算模型训练过程中的各个数据情况\n",
    "## 4.1 tf.keras.metrics模块计算均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.5>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# tf.keras.metrics.Mean用于计算均值，这里是计算准确率的均值\n",
    "m = tf.keras.metrics.Mean('acc')\n",
    "# 如果需要计算一些数值的均值，可以是一个一个的传入到m(value)中，最后再使用m.result()\n",
    "# m(10)\n",
    "# m(20)\n",
    "# m.result()\n",
    "# 或者直接给一个列表进行计算\n",
    "m([10, 20, 30, 50])\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于重置状态(避免记录上面的结果影响后面的计算)\n",
    "m.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 tf.keras.metrics计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=270449, shape=(), dtype=float32, numpy=0.09375>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.keras.metrics.SparseCategoricalAccuracy('acc')\n",
    "# a(y, y_hat)\n",
    "a(labels, model(features))\n",
    "a.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}